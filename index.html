<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="UCLA COM SCI 188 Final Project by Joe Lin, Allen Luo, and Nishant Ray">
  <meta property="og:title" content="From Words to Actions: Language-Guided Hierarchical RL for Object Rearrangement"/>
  <meta property="og:description" content="UCLA COM SCI 188 Final Project by Joe Lin, Allen Luo, and Nishant Ray"/>
  <meta property="og:url" content="https://joe-lin-tech.github.io/robotics-website.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/SOME IMAGE.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  
  
  <meta name="twitter:title" content="From Words to Actions: Language-Guided Hierarchical RL for Object Rearrangement">
  <meta name="twitter:description" content="UCLA COM SCI 188 Final Project by Joe Lin, Allen Luo, and Nishant Ray">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/SOME IMAGE.png">

  <meta name="viewport" content="width=device-width, initial-scale=1">  
  
  <title>From Words to Actions: Language-Guided Hierarchical RL for Object Rearrangement</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>
  <!-- Tagline + image carousel -->
  <section class="hero section">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-four-fifths has-text-centered">
            <h1 class="title is-1 publication-title">From Words to Actions: Language-Guided Hierarchical RL for Object Rearrangement</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Joe Lin,</span>
              <span class="author-block">Allen Luo,</span>
              <span class="author-block">Nishant Ray</span>
            </div>
                
            <div class="is-size-5 publication-authors">
              <span class="author-block">UCLA<br>COM SCI 188 - Final Project</span>
            </div>
            
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Paper PDF link -->
                <span class="link-block">
                  <a href="hhtps://ADD PAPER LINK" target="_blank" class="external-link button is-normal is-rounded is-link">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/joe-lin-tech/robotics" target="_blank" class="external-link button is-normal is-rounded is-link">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
      <br><br><br>
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img class="image" src="static/images/carousel4.jpg" alt="MY ALT TEXT" data-tilt data-tilt-reverse="true" data-tilt-max="2"/>
            <h2 class="subtitle has-text-centered">
              First image description.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img class="image" src="static/images/carousel4.jpg" alt="MY ALT TEXT" data-tilt data-tilt-reverse="true" data-tilt-max="2"/>
            <h2 class="subtitle has-text-centered">
              Second image description.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img class="image" src="static/images/carousel4.jpg" alt="MY ALT TEXT" data-tilt data-tilt-reverse="true" data-tilt-max="2"/>
            <h2 class="subtitle has-text-centered">
              Third image description.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img class="image" src="static/images/carousel4.jpg" alt="MY ALT TEXT" data-tilt data-tilt-reverse="true" data-tilt-max="2"/>
            <h2 class="subtitle has-text-centered">
              Fourth image description.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End tagline + image carousel -->
  
  <!-- Paper abstract -->
  <section class="section hero bright">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We explore the use of natural language to guide hierarchical reinforcement learning (HRL) agents 
              in long-horizon indoor rearrangement tasks. Using the Habitat Lab framework and the ReplicaCAD 
              <i>rearrange_easy</i> benchmark, we train a high-level policy to select among pre-trained low-level 
              skills based on both visual observations and language instructions. To fuse multimodal inputs, 
              we evaluate two techniques: FiLM and cross-attention. Language 
              instructions are generated using a large language model and embedded via a pretrained CLIP 
              encoder. Our results show that incorporating language slightly improves task performance; 
              however, the overall success rate remains low due to compounding errors from unreliable 
              low-level skills. This suggests that while language offers valuable context, its benefits 
              are limited without reliable underlying skills. We discuss key challenges and propose directions 
              for mitigating cascading failures.  
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->
  
  <!-- Youtube video -->
  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video Demo</h2>
            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End youtube video -->
  
  <!-- Paper introduction -->
  <section class="section hero bright">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Intro</h2>
          <div class="content has-text-justified">
            <ul>
              <li>
                Teaching embodied agents to perform everyday, complex tasks in 3D environments is a core challenge in embodied AI
              </li>
              <li>
                Reinforcement learning (RL) shows promise but is difficult to scale to long-horizon tasks due to sparse rewards & large action spaces
              </li>
              <li>
                HRL offers a natural solution by decomposing tasks into reusable low-level skills orchestrated by a high-level policy
              </li>
              <li>
                Multimodal learning research shows that natural language can specify high-level goals for agents
              </li>
              <li>
                We've extended the Habitat Lab framework to incorporate natural language instructions into the high-level controller to pick low-level skills conditioned on language & visual observations
              </li>
              <li>
                We've exploreed methods such as feature-wise linear modulation (FiLM) and cross-attention mechanisms to fuse language with vision
              </li>
              <li>
                We've built on ReplicaCAD's "rearrange_easy" benchmark, auto-generating scene descriptions to create paired language-visual tasks
              </li>
              <li>
                We've evaluated how language-conditioned HRL agents perform against purely vision-based baselines
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper introduction -->

  <!-- Paper goal -->
  <section class="section hero">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Goal</h2>
          <div class="content">
            <p>
              We aim to create a hierarchical agent that can:
            </p>
            <div class="goals-container">
              <div class="goal-card">
                <h4>Interpret a natural language goal & use it to guide skill selection</h4>
              </div>
              <div class="goal-card">
                <h4>Combine language & visual input to improve task performance & generalization</h4>
              </div>
              <div class="goal-card">
                <h4>Train & evaluate on realistic 3D rearrangement tasks with varying scenes</h4>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper goal -->

  <!-- Paper methods -->
  <section class="section hero bright">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Methods</h2>
          <div class="content">
            <div class="methods-container">
              <div class="method-card">
                <h4>Dataset</h4>
                <ul>
                  <li>
                    ReplicaCAD offers a "FRL apartment" environment for Habitat simulation
                  </li>
                  <li>
                    "rearrange_easy" subset has a training split of 50,000 episodes of rearrangement problems over 63 scenes & validation split with 1,000 episodes from another 21 scenes 
                  </li>
                  <li>
                    Language augmentation pipeline:
                    <ol style="margin-top: 5px">
                      <li>
                        Extract target object and goal locations from each episode
                      </li>
                      <li>
                        Map provided indices to scene receptacle locations
                      </li>
                      <li>
                        Generate template sentences for each episode
                      </li>
                      <li>
                        Reword into natural language via Google Gemini 2.0 Flash
                      </li>
                      <li>
                        Transform into feature vectors with OpenAI's ViT-B/32 CLIP model 
                      </li>
                    </ol>
                  </li>
                </ul>
              </div>
              <div class="method-card">
                <h4>Low-Level Skills Training</h4>
                <ul>
                  <li>
                    Habitat Lab provides framework for training low-level skills composed by a high-level policy in a HRL environment
                  </li>
                  <li>
                    These skills correspond to separate, reusable behaviors (like picking or placing objects) & are trained independently using Proximal Policy Optimization (PPO)
                  </li>
                  <li>
                    We use the following 3 low-level skills provided by Habitat Lab:
                    <ol style="margin-top: 5px">
                      <li>
                        pick
                      </li>
                      <li>
                        place
                      </li>
                      <li>
                        navigate
                      </li>
                    </ol>
                  </li>
                </ul>
              </div>
              <div class="method-card">
                <h4>HRL Training</h4>
                <ul>
                  <li>
                    We train a HRL agent based on Habitat Lab's benchmark to create a high-level policy that picks between pre-trained low-level skills
                  </li>
                  <li>
                    High-level policy receives visual observations and language instructions as input, and outputs sequence of skills with appropriate parameters
                  </li>
                  <li>
                    The model is also given the target object + position along with goal position
                  </li>
                  <li>
                    We experiment with a baseline with no language input, visual feature conditioning through FiLM, and cross-attention visual & language feature fusion
                  </li>
                  <li>
                    <b>Baseline:</b> benchmark provided by Habitat Lab; visual observations transformed into 
                    features through the provided ResNet-18 encoder, and then fed into a recurrent policy 
                    network trained with PPO (agent is not conditioned on language input)
                  </li>
                  <li>
                    <b>FiLM:</b> we insert FiLM layers into every ResNet residual block that take CLIP 
                    language embeddings and produce per-block γ (scale) and β (shift) parameters to 
                    modulate the visual feature maps before the ReLU, enabling instruction-conditioned 
                    extraction of task-relevant cues
                  </li>
                  <li>
                    <b>Cross-Attention:</b> We integrate a cross-attention block into the ResNet encoder that
                    uses language embeddings as the query and ResNet visual features as key/value pairs,
                    enabling selective attention to spatial regions most relevant to the instruction.
                  </li>
                </ul>

                <img class="method-image" src="static/images/vision_language_pipeline.png" alt="Vision language pipeline" data-tilt data-tilt-reverse="true" data-tilt-max="2"/>
              </div>
              <div class="method-card">
                <h4>Reward Function Design</h4>
                <ul>
                  <li>
                    Habitat Lab uses "pddl_subgoal_reward" as its reward signal, which is a sparse reward based on the completion of intermediary goals
                  </li>
                  <li>
                    During training we notice the agent struggles to learn from sparse rewards, so we augment the original reward with dense terms to build a dense reward signal, "CompositeReward":
                  </li>
                </ul>

                <img class="method-image" src="static/images/dense_reward_signal.png" alt="Dense reward signal" data-tilt data-tilt-reverse="true" data-tilt-max="2"/>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper methods -->

  <!-- Paper results -->
  <section class="section hero">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
          <div class="content">
            <div class="results-container">
              <div class="result-card">
                <h4>Low-Level Skills</h4>
                <ul>
                  <li>
                    Training low-level skill policies was challenging and tedious due to data-hungriness and limited GPU hardware 
                  </li>
                  <li>
                    We achieved ≈60%, ≈55%, and ≈80% on pick, place, navigate, respectively
                  </li>
                  <li>
                    Below are our success rate and training curves:
                  </li>
                </ul>
                <img class="method-image" src="static/images/result_curves.png" alt="Dense reward signal" data-tilt data-tilt-reverse="true" data-tilt-max="2"/>
                <ul>
                  <li>
                    "action_loss" and "value_loss" were unrepresentative of training progress as expected, unlike "reward"
                  </li>
                  <li>
                    Agent excels at learning "navigate" but struggles with "pick" and "place", often plateauing in success rate
                  </li>
                  <li>
                    Most likely since "navigate" is a high-level locomotion task that requires less degrees of freedom to solve, 
                    whereas "pick" & "place" suffer from higher-order complexities
                  </li>
                </ul>
              </div>
              <div class="result-card">
                <h4>High-Level Neural Policy</h4>
                <ul>
                  <li>
                    Compounding errors from low-level policies led to difficulties with training high-level policy
                  </li>
                  <li>
                    Achieved ≈5% success rate for rearrangement task, whereas the baseline achieves ≈X%
                  </li>
                  <li>
                    We infer the agent learns to prefer inaction to avoid negative rewards, as during training, the agent hones in 
                    on the "navigate" skill and achieves positive reward learning progress, but progress then halts at a success 
                    rate of 5% which then plummets, all while rollout durations and object collisions reduce drastically
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper results -->

  <!-- Paper discussion -->
  <section class="section hero bright">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Discussion</h2>
          <div class="content has-text-justified">
            <p>
              Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin ullamcorper tellus sed ante aliquam tempus. Etiam porttitor urna feugiat nibh elementum, et tempor dolor mattis. Donec accumsan enim augue, a vulputate nisi sodales sit amet. Proin bibendum ex eget mauris cursus euismod nec et nibh. Maecenas ac gravida ante, nec cursus dui. Vivamus purus nibh, placerat ac purus eget, sagittis vestibulum metus. Sed vestibulum bibendum lectus gravida commodo. Pellentesque auctor leo vitae sagittis suscipit.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper discussion -->

  <!-- Paper conclusion -->
  <section class="section hero">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Conclusion</h2>
          <div class="content has-text-justified">
            <p>
              Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin ullamcorper tellus sed ante aliquam tempus. Etiam porttitor urna feugiat nibh elementum, et tempor dolor mattis. Donec accumsan enim augue, a vulputate nisi sodales sit amet. Proin bibendum ex eget mauris cursus euismod nec et nibh. Maecenas ac gravida ante, nec cursus dui. Vivamus purus nibh, placerat ac purus eget, sagittis vestibulum metus. Sed vestibulum bibendum lectus gravida commodo. Pellentesque auctor leo vitae sagittis suscipit.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper conclusion -->
  
  <!-- Full paper -->
  <section class="hero bright">
    <div class="hero-body">
      <div class="container">
        <div class="column is-centered has-text-centered">
          <h2 class="title">Full Paper</h2>
          <iframe src="static/pdfs/sample.pdf" width="100%" height="550"></iframe>
        </div>
      </div>
    </div>
  </section>
  <!--End full paper -->
  
  <footer class="footer">
    <div class="container">
      <div class="columns has-text-centered is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Created for UCLA's COM SCI 188 Final Project
            </p>
          </div>
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
  
  <script type="text/javascript" src="static/js/vanilla-tilt.js"></script>
</body>
</html>
